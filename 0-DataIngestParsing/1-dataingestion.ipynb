{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da05d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f94ebb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00673407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: This is the main text content that will be embedded and searched.\n",
      "Metadata: {'source': 'example.txt', 'page': 1, 'author': 'Krish Naik', 'date_created': '2024-01-01', 'custom_field': 'any_value'}\n"
     ]
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\", \n",
    "    metadata={\"\"\n",
    "    \"source\": \"example.txt\",\n",
    "    \"page\": 1,\n",
    "    \"author\": \"Krish Naik\",\n",
    "    \"date_created\": \"2024-01-01\",\n",
    "    \"custom_field\": \"any_value\"\n",
    "    }\n",
    ")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461ead51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5c5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created successfully.\n"
     ]
    }
   ],
   "source": [
    "sample_text = {\n",
    "    \"data/text_files/python_intro.txt\": \"\"\"\n",
    "    This is the content of file one. It contains important information about LangChain. \n",
    "    LangChain is a powerful library for building applications with language models.\n",
    "    \n",
    "    \n",
    "    It provides tools for data ingestion, parsing, and embedding.\n",
    "    and more.\n",
    "    \n",
    "    Key features include document loaders, text splitters, and vector stores.\n",
    "    Python is a versatile programming language used for various applications, including web development, data analysis, and artificial intelligence.\n",
    "\n",
    "\n",
    "    Learning Python can open up many career opportunities in the tech industry.\n",
    "    \"\"\",\n",
    "    \n",
    "}\n",
    "\n",
    "for filepath, content in sample_text.items():\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text files created successfully.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57a1aa",
   "metadata": {},
   "source": [
    "## File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d8ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "## Loading single text file\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "print(type(documents))\n",
    "print(documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d283d9",
   "metadata": {},
   "source": [
    "## Directory loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cdd10b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1501.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "  Source: data/text_files/python_intro.txt\n",
      "  Length of content: 570 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Loading all text files from a directory\n",
    "directory_loader = DirectoryLoader(\n",
    "    \"data/text_files\", \n",
    "    glob=\"**/*.txt\", ## pattern to match files\n",
    "    loader_cls=TextLoader, ## loader class to use\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "documents = directory_loader.load()\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length of content: {len(doc.page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559247e9",
   "metadata": {},
   "source": [
    "## Test splittings strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be7b0e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='\\n    This is the content of file one. It contains important information about LangChain. \\n    LangChain is a powerful library for building applications with language models.\\n\\n\\n    It provides tools for data ingestion, parsing, and embedding.\\n    and more.\\n\\n    Key features include document loaders, text splitters, and vector stores.\\n    Python is a versatile programming language used for various applications, including web development, data analysis, and artificial intelligence.\\n\\n\\n    Learning Python can open up many career opportunities in the tech industry.\\n    ')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import ( \n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a56d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    This is the content of file one. It contains important information about LangChain. \\n    LangChain is a powerful library for building applications with language models.\\n\\n\\n    It provides tools for data ingestion, parsing, and embedding.\\n    and more.\\n\\n    Key features include document loaders, text splitters, and vector stores.\\n    Python is a versatile programming language used for various applications, including web development, data analysis, and artificial intelligence.\\n\\n\\n    Learning Python can open up many career opportunities in the tech industry.\\n    '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Method 1 - CHaracter Text Splitter\n",
    "text=documents[0].page_content\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ffe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CHARACTER TEXT SPLITTER\n",
      "Number of chunks: 4\n",
      "First chunk:\n",
      "This is the content of file one. It contains important information about LangChain. \n",
      "    LangChain i...\n",
      "This is the content of file one. It contains important information about LangChain. \n",
      "    LangChain is a powerful library for building applications with language models.\n"
     ]
    }
   ],
   "source": [
    "print(\"1 CHARACTER TEXT SPLITTER\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200, \n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "char_chunks=char_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(char_chunks)}\")\n",
    "print(f\"First chunk:\\n{char_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789faf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28602442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the content of file one. It contains important information about LangChain. \n",
      "    LangChain is a powerful library for building applications with language models.\n",
      "It provides tools for data ingestion, parsing, and embedding.\n",
      "    and more.\n",
      "    Key features include document loaders, text splitters, and vector stores.\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(char_chunks[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac2bc798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Recursive CHARACTER TEXT SPLITTER\n",
      "Number of chunks: 5\n",
      "First chunk:\n",
      "This is the content of file one. It contains important information about LangChain. \n",
      "    LangChain i...\n"
     ]
    }
   ],
   "source": [
    "print(\"2 Recursive CHARACTER TEXT SPLITTER\")\n",
    "recursive_char_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=200, \n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_char_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(recursive_chunks)}\")\n",
    "print(f\"First chunk:\\n{recursive_chunks[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8367a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the content of file one. It contains important information about LangChain. \n",
      "    LangChain is a powerful library for building applications with language models.\n",
      "SPLITTER\n",
      "It provides tools for data ingestion, parsing, and embedding.\n",
      "    and more.\n",
      "SPLITTER\n",
      "Key features include document loaders, text splitters, and vector stores.\n",
      "SPLITTER\n",
      "Python is a versatile programming language used for various applications, including web development, data analysis, and artificial intelligence.\n",
      "SPLITTER\n",
      "Learning Python can open up many career opportunities in the tech industry.\n"
     ]
    }
   ],
   "source": [
    "print(recursive_chunks[0])\n",
    "print(\"SPLITTER\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"SPLITTER\")\n",
    "print(recursive_chunks[2])\n",
    "print(\"SPLITTER\")\n",
    "print(recursive_chunks[3])\n",
    "print(\"SPLITTER\")\n",
    "print(recursive_chunks[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "First chunk:\n",
      "\n",
      "    This is the content of file one. It contains important information about LangChain. \n",
      "    LangCh...\n"
     ]
    }
   ],
   "source": [
    "# Method3: Token based splitter\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50, #calculate spaces and not only characters\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(token_chunks)}\")\n",
    "print(f\"First chunk:\\n{token_chunks[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "print(\"\\nðŸ“Š Text Splitting Methods Comparison:\")\n",
    "print(\"\\nCharacterTextSplitter:\")\n",
    "print(\"  âœ… Simple and predictable\")\n",
    "print(\"  âœ… Good for structured text\")\n",
    "print(\"  âŒ May break mid-sentence\")\n",
    "print(\"  Use when: Text has clear delimiters\")\n",
    "\n",
    "print(\"\\nRecursiveCharacterTextSplitter:\")\n",
    "print(\"  âœ… Respects text structure\")\n",
    "print(\"  âœ… Tries multiple separators\")\n",
    "print(\"  âœ… Best general-purpose splitter\")\n",
    "print(\"  âŒ Slightly more complex\")\n",
    "print(\"  Use when: Default choice for most texts\")\n",
    "\n",
    "print(\"\\nTokenTextSplitter:\")\n",
    "print(\"  âœ… Respects model token limits\")\n",
    "print(\"  âœ… More accurate for embeddings\")\n",
    "print(\"  âŒ Slower than character-based\")\n",
    "print(\"  Use when: Working with token-limited models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e03e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d7fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
